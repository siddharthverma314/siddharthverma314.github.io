<!DOCTYPE HTML>
<html><head><title>Siddharth Verma</title><link rel="stylesheet" href="style.css"><meta content="text/html;charset=utf-8" http-equiv="Content-Type"><meta content="utf-8" http-equiv="encoding"><meta name="viewport" content="width=device-width, initial-scale=1.0"></head><body onload="init()"><script src="index.js"></script><div class="bg-indigo-800 text-slate-200"><div class="flex flex-row p-4"><div class="px-1.5 md:px-3 first:flex-1"><a class="text-slate-300 hover:text-slate-500" href="siddharthverma314.github.io">Siddharth Verma</a></div><div class="px-1.5 md:px-3 first:flex-1"><a class="text-slate-300 hover:text-slate-500" href="/resume.pdf"><svg height="20px" viewBox="0 0 28 34" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M2.20239 5V29C2.20239 30.6569 3.54554 32 5.20239 32H23.2024C24.8593 32 26.2024 30.6569 26.2024 29V11.5124C26.2024 10.7051 25.877 9.93184 25.2997 9.36742L18.6392 2.85498C18.0787 2.30688 17.326 2 16.5419 2H5.20239C3.54554 2 2.20239 3.34314 2.20239 5V5Z" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/>
<path d="M17.2024 2V8C17.2024 9.65685 18.5455 11 20.2024 11H26.2024" stroke="currentColor" stroke-width="3" stroke-linejoin="round"/>
</svg>
</a></div><div class="px-1.5 md:px-3 first:flex-1"><a class="text-slate-300 hover:text-slate-500" href="https://www.linkedin.com/in/siddharth-verma/"><svg height="20px" viewBox="0 0 31 30" fill="none" xmlns="http://www.w3.org/2000/svg">
<mask id="path-1-inside-1_33_864" fill="white">
<path fill-rule="evenodd" clip-rule="evenodd" d="M0.202393 2.50625C0.202393 1.84155 0.466446 1.20408 0.936458 0.734065C1.40647 0.264053 2.04394 0 2.70864 0H27.6961C28.0252 0 28.3512 0.0648302 28.6551 0.190781C28.9592 0.316733 29.2355 0.501336 29.4683 0.734065C29.701 0.966794 29.8856 1.24308 30.0116 1.54714C30.1375 1.85122 30.2024 2.17712 30.2024 2.50625V27.4937C30.2024 27.8229 30.1375 28.1488 30.0116 28.4527C29.8856 28.7569 29.701 29.0331 29.4683 29.2659C29.2355 29.4986 28.9592 29.6832 28.6551 29.8092C28.3512 29.9351 28.0252 30 27.6961 30H2.70864C2.04394 30 1.40647 29.7359 0.936458 29.2659C0.466446 28.7959 0.202393 28.1585 0.202393 27.4937V2.50625ZM12.0774 11.4375H16.1399V13.4788C16.7255 12.3049 18.2261 11.25 20.4804 11.25C24.8017 11.25 25.8274 13.5863 25.8274 17.873V25.8125H21.4524V18.8493C21.4524 16.4082 20.8668 15.0312 19.3774 15.0312C17.3118 15.0312 16.4524 16.5156 16.4524 18.8493V25.8125H12.0774V11.4375ZM4.57738 25.625H8.95239V11.25H4.57738V25.625ZM9.57738 6.56248C9.57738 6.93183 9.50463 7.29756 9.3633 7.63878C9.22195 7.98001 9.01478 8.29006 8.75361 8.55122C8.49245 8.81238 8.1824 9.01956 7.84118 9.1609C7.49995 9.30224 7.13422 9.37499 6.76488 9.37499C6.39555 9.37499 6.02982 9.30224 5.68859 9.1609C5.34735 9.01956 5.03732 8.81238 4.77614 8.55122C4.51498 8.29006 4.30782 7.98001 4.16647 7.63878C4.02514 7.29756 3.95239 6.93183 3.95239 6.56248C3.95239 5.81657 4.2487 5.1012 4.77614 4.57375C5.30359 4.04631 6.01896 3.74999 6.76488 3.74999C7.51081 3.74999 8.22618 4.04631 8.75361 4.57375C9.28106 5.1012 9.57738 5.81657 9.57738 6.56248Z"/>
</mask>
<path fill-rule="evenodd" clip-rule="evenodd" d="M0.202393 2.50625C0.202393 1.84155 0.466446 1.20408 0.936458 0.734065C1.40647 0.264053 2.04394 0 2.70864 0H27.6961C28.0252 0 28.3512 0.0648302 28.6551 0.190781C28.9592 0.316733 29.2355 0.501336 29.4683 0.734065C29.701 0.966794 29.8856 1.24308 30.0116 1.54714C30.1375 1.85122 30.2024 2.17712 30.2024 2.50625V27.4937C30.2024 27.8229 30.1375 28.1488 30.0116 28.4527C29.8856 28.7569 29.701 29.0331 29.4683 29.2659C29.2355 29.4986 28.9592 29.6832 28.6551 29.8092C28.3512 29.9351 28.0252 30 27.6961 30H2.70864C2.04394 30 1.40647 29.7359 0.936458 29.2659C0.466446 28.7959 0.202393 28.1585 0.202393 27.4937V2.50625ZM12.0774 11.4375H16.1399V13.4788C16.7255 12.3049 18.2261 11.25 20.4804 11.25C24.8017 11.25 25.8274 13.5863 25.8274 17.873V25.8125H21.4524V18.8493C21.4524 16.4082 20.8668 15.0312 19.3774 15.0312C17.3118 15.0312 16.4524 16.5156 16.4524 18.8493V25.8125H12.0774V11.4375ZM4.57738 25.625H8.95239V11.25H4.57738V25.625ZM9.57738 6.56248C9.57738 6.93183 9.50463 7.29756 9.3633 7.63878C9.22195 7.98001 9.01478 8.29006 8.75361 8.55122C8.49245 8.81238 8.1824 9.01956 7.84118 9.1609C7.49995 9.30224 7.13422 9.37499 6.76488 9.37499C6.39555 9.37499 6.02982 9.30224 5.68859 9.1609C5.34735 9.01956 5.03732 8.81238 4.77614 8.55122C4.51498 8.29006 4.30782 7.98001 4.16647 7.63878C4.02514 7.29756 3.95239 6.93183 3.95239 6.56248C3.95239 5.81657 4.2487 5.1012 4.77614 4.57375C5.30359 4.04631 6.01896 3.74999 6.76488 3.74999C7.51081 3.74999 8.22618 4.04631 8.75361 4.57375C9.28106 5.1012 9.57738 5.81657 9.57738 6.56248Z" fill="currentColor" stroke="currentColor" stroke-width="10.9494" mask="url(#path-1-inside-1_33_864)"/>
</svg>
</a></div><div class="px-1.5 md:px-3 first:flex-1"><a class="text-slate-300 hover:text-slate-500" href="https://scholar.google.com/citations?user=B320e3kAAAAJ"><svg height="20px" viewBox="0 0 27 30" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M6.77382 8.85714H0.202393L10.2747 0H26.9167L20.0595 5.71429C20.083 5.77894 20.1129 5.8564 20.1469 5.94488L20.147 5.94493C20.3889 6.57333 20.8448 7.75749 20.7738 8.85714C20.6023 11.516 19.1949 12.6815 18.0974 13.5903C17.367 14.1952 16.7738 14.6864 16.7738 15.4286C16.7738 16.612 17.6562 17.2563 18.69 18.011C20.1519 19.0785 21.9167 20.3669 21.9167 23.7143C22.0595 27.8571 17.631 30 13.631 30C10.1895 30 5.48811 29 4.91668 25.4286C4.34525 21.8571 9.20239 18.2857 14.7738 18.8571C13.7116 17.7949 13.2024 16.5714 13.9167 15C11.9167 15 10.3738 14.5714 8.77382 13.4286C7.17382 12.2857 6.77382 9.90476 6.77382 8.85714ZM15.7738 13.7143C13.7738 14.7143 11.2023 12.7143 10.2023 10.4286C9.20235 8.14286 9.77376 4.85716 11.9166 4.00001C14.0595 3.14286 16.3452 5.14285 17.3452 7.42857C18.3452 9.71428 17.7738 12.7143 15.7738 13.7143ZM16.7915 20.3874C17.9357 21.1149 19.6543 22.2076 19.7738 24C19.9167 26.8571 18.0595 28.5714 13.9167 28.5714C9.77383 28.5714 8.05954 26.1429 8.05954 24.2857C8.05954 20.7143 12.3453 19 16.2024 20C16.366 20.1168 16.5677 20.2451 16.7915 20.3874Z" fill="currentColor"/>
</svg>
</a></div><div class="px-1.5 md:px-3 first:flex-1"><a class="text-slate-300 hover:text-slate-500" href="https://twitter.com/sidv314"><svg width="20px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 248 204">
  <path fill="currentColor" d="M221.95 51.29c.15 2.17.15 4.34.15 6.53 0 66.73-50.8 143.69-143.69 143.69v-.04c-27.44.04-54.31-7.82-77.41-22.64 3.99.48 8 .72 12.02.73 22.74.02 44.83-7.61 62.72-21.66-21.61-.41-40.56-14.5-47.18-35.07 7.57 1.46 15.37 1.16 22.8-.87-23.56-4.76-40.51-25.46-40.51-49.5v-.64c7.02 3.91 14.88 6.08 22.92 6.32C11.58 63.31 4.74 33.79 18.14 10.71c25.64 31.55 63.47 50.73 104.08 52.76-4.07-17.54 1.49-35.92 14.61-48.25 20.34-19.12 52.33-18.14 71.45 2.19 11.31-2.23 22.15-6.38 32.07-12.26-3.77 11.69-11.66 21.62-22.2 27.93 10.01-1.18 19.79-3.86 29-7.95-6.78 10.16-15.32 19.01-25.2 26.16z"/>
</svg>
</a></div><div class="px-1.5 md:px-3 first:flex-1"><a class="text-slate-300 hover:text-slate-500" href="https://github.com/siddharthverma314"><svg width="20px" viewBox="0 0 31 30" xmlns="http://www.w3.org/2000/svg">
<mask id="path-1-inside-1_33_842" fill="white">
<path fill-rule="evenodd" clip-rule="evenodd" d="M15.2024 0C6.91489 0 0.202393 6.88228 0.202393 15.3794C0.202393 22.1848 4.49614 27.9328 10.4586 29.9706C11.2086 30.1052 11.4899 29.6438 11.4899 29.2401C11.4899 28.8748 11.4711 27.6637 11.4711 26.3757C7.70239 27.087 6.72739 25.4337 6.42739 24.5686C6.25864 24.1264 5.52739 22.7615 4.88989 22.3963C4.36489 22.1079 3.61489 21.3966 4.87114 21.3774C6.05239 21.3582 6.89614 22.4924 7.17739 22.9538C8.52739 25.2799 10.6836 24.6263 11.5461 24.2226C11.6774 23.2229 12.0711 22.5501 12.5024 22.1656C9.16489 21.7811 5.67739 20.4546 5.67739 14.572C5.67739 12.8995 6.25864 11.5153 7.21489 10.4388C7.06489 10.0543 6.53989 8.4779 7.36489 6.36323C7.36489 6.36323 8.62114 5.95952 11.4899 7.93962C12.6899 7.59358 13.9649 7.42056 15.2399 7.42056C16.5149 7.42056 17.7899 7.59358 18.9899 7.93962C21.8586 5.9403 23.1149 6.36323 23.1149 6.36323C23.9399 8.4779 23.4149 10.0543 23.2649 10.4388C24.2211 11.5153 24.8024 12.8803 24.8024 14.572C24.8024 20.4738 21.2961 21.7811 17.9586 22.1656C18.5024 22.6462 18.9711 23.5689 18.9711 25.0108C18.9711 27.0678 18.9524 28.721 18.9524 29.2401C18.9524 29.6438 19.2336 30.1244 19.9836 29.9706C22.9614 28.9399 25.549 26.9778 27.3821 24.3602C29.2153 21.7428 30.2016 18.6018 30.2024 15.3794C30.2024 6.88228 23.4899 0 15.2024 0V0Z"/>
</mask>
<path fill-rule="evenodd" clip-rule="evenodd" d="M15.2024 0C6.91489 0 0.202393 6.88228 0.202393 15.3794C0.202393 22.1848 4.49614 27.9328 10.4586 29.9706C11.2086 30.1052 11.4899 29.6438 11.4899 29.2401C11.4899 28.8748 11.4711 27.6637 11.4711 26.3757C7.70239 27.087 6.72739 25.4337 6.42739 24.5686C6.25864 24.1264 5.52739 22.7615 4.88989 22.3963C4.36489 22.1079 3.61489 21.3966 4.87114 21.3774C6.05239 21.3582 6.89614 22.4924 7.17739 22.9538C8.52739 25.2799 10.6836 24.6263 11.5461 24.2226C11.6774 23.2229 12.0711 22.5501 12.5024 22.1656C9.16489 21.7811 5.67739 20.4546 5.67739 14.572C5.67739 12.8995 6.25864 11.5153 7.21489 10.4388C7.06489 10.0543 6.53989 8.4779 7.36489 6.36323C7.36489 6.36323 8.62114 5.95952 11.4899 7.93962C12.6899 7.59358 13.9649 7.42056 15.2399 7.42056C16.5149 7.42056 17.7899 7.59358 18.9899 7.93962C21.8586 5.9403 23.1149 6.36323 23.1149 6.36323C23.9399 8.4779 23.4149 10.0543 23.2649 10.4388C24.2211 11.5153 24.8024 12.8803 24.8024 14.572C24.8024 20.4738 21.2961 21.7811 17.9586 22.1656C18.5024 22.6462 18.9711 23.5689 18.9711 25.0108C18.9711 27.0678 18.9524 28.721 18.9524 29.2401C18.9524 29.6438 19.2336 30.1244 19.9836 29.9706C22.9614 28.9399 25.549 26.9778 27.3821 24.3602C29.2153 21.7428 30.2016 18.6018 30.2024 15.3794C30.2024 6.88228 23.4899 0 15.2024 0V0Z" fill="currentColor" stroke="currentColor" stroke-width="10.0365" mask="url(#path-1-inside-1_33_842)"/>
</svg>
</a></div></div><div class="flex flex-col items-center py-5"><div class="p-4 w-full max-w-xl text-rose-300"><svg viewBox="0 0 2945 698" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M2240.03 246.574C2243.6 251.092 2242.21 261.185 2234.25 288.515C2230.59 301.097 2227.28 313.089 2226.89 315.162C2225.15 324.494 2231.84 334.279 2242.24 337.617C2267.18 345.631 2284.56 363.547 2284.51 381.198C2284.47 394.39 2272.99 434.623 2266.24 445.229C2259.88 455.225 2219.88 531.54 2244.08 537.148C2285.43 541.828 2346.82 409.602 2365.37 380.673C2400.52 325.85 2424.56 314.501 2437.03 346.843C2438.77 351.373 2440.69 358.935 2441.28 363.645C2443.15 378.571 2446.02 378.421 2457.17 362.814C2485.64 322.931 2531.55 313.872 2539.51 352.23C2541.46 361.606 2542.87 361.15 2555.31 347.135C2580.13 319.172 2607.47 326.641 2621.63 342.773C2635.53 358.614 2640.91 391.882 2633.62 416.887C2624.11 449.477 2609.82 478.036 2595.15 508.635C2584.78 530.255 2589.44 544.434 2611 523.319C2652.39 482.785 2651.4 483.998 2653.28 471.591C2662.5 410.628 2712.1 333.114 2779.23 327.024C2791.45 325.914 2808.64 332.697 2825.28 345.194C2831.19 349.637 2833.36 349.554 2837.56 344.721C2839.44 342.556 2843.44 337.95 2846.46 334.486C2855.89 323.663 2864.31 319.746 2869.54 323.76C2880.34 332.058 2875.74 345.194 2866.18 363.878C2856.62 382.561 2782.11 489.829 2794.8 532.22C2798.25 543.755 2814.21 542.125 2835.88 528.022C2876.19 501.781 2904.6 473.048 2932.53 432.804C2938.37 424.384 2941.22 421.675 2943.37 422.5C2958.51 428.316 2863.42 525.942 2854.24 532.235C2829.7 549.052 2780.6 577.003 2768.78 530.255C2765.25 516.267 2763.33 503.57 2750.36 516.684C2711.02 556.447 2681.67 554.785 2661.19 511.636C2652.65 493.645 2650.64 506.236 2634.29 524.154C2611.19 549.467 2593.66 545.475 2593.66 545.475C2532.77 545.117 2580.14 432.899 2596.68 400.102C2612.42 368.901 2585.85 333.204 2561.38 366.341C2540.71 394.344 2517.42 501.068 2486.01 535.503C2479.24 542.926 2472.09 543.211 2464.5 542.851C2436.67 541.528 2519.26 369.405 2513.96 348.263C2509.7 331.291 2480.73 352.369 2461.65 381.722C2441.65 412.473 2415.84 517.105 2381.63 540.751C2377.04 543.923 2371.27 542.851 2366.41 542.851C2334.8 542.851 2401.72 404.397 2408.53 388.448C2415.63 371.802 2417.62 353.496 2412.79 349.121C2398.07 335.794 2294.06 558.4 2241.13 542.233C2178.46 523.089 2226.85 430.238 2251.59 394.319C2270.76 366.488 2271.58 368.728 2233.54 345.104C2217.83 335.348 2216.02 335.848 2207.8 352.23C2180.7 406.254 2119.8 580.502 2036.48 537.609C1998.33 517.969 1984.63 473.091 2000.25 418.91C2004.91 402.743 2027.46 369.585 2039.66 360.956C2043.1 358.522 2049.34 354.059 2053.52 351.039C2088.62 325.711 2134.83 325.382 2140.17 350.423C2146.54 380.312 2101.26 427.483 2045.09 449.471C2018.85 459.743 2017.62 526.14 2043.53 533.341C2089.23 546.037 2224.78 364.462 2203.19 316.029C2194.44 296.404 2199.16 273.879 2216 254.791C2225.5 244.027 2235.36 240.658 2240.03 246.574ZM2045.94 427.009C2046.01 415.687 2097.75 351.763 2110.75 346.932C2142.2 335.247 2131.45 373.382 2095.75 400.15C2088.25 405.774 2078.69 413 2074.5 416.207C2059.65 427.591 2045.9 432.79 2045.94 427.009ZM2779.27 460.23C2771.97 476.806 2774.38 476.447 2756.4 493.899C2740.12 509.702 2689.26 545.499 2678.46 512.773C2662.99 465.855 2732.07 370.89 2777.65 349.086C2789.63 343.359 2812.75 348.506 2816.61 357.76C2820.36 366.722 2818.71 385.419 2805.98 406.39C2796.97 421.233 2786.57 443.654 2779.27 460.23Z" fill="currentColor" />
<path fill-rule="evenodd" clip-rule="evenodd" d="M2064.33 194.829C2068.79 199.3 2067.83 204.817 2055.79 243.687C2048.39 267.546 2042.76 283.12 2035.67 299.321C2016.54 343.01 1995.33 388.78 1966.19 426.891C1944.81 454.852 1918.59 482.834 1902.14 514.008C1882.2 551.821 1880.1 554.387 1869.13 554.393C1851.57 554.405 1848.74 546.484 1848.67 497.189C1848.56 422.264 1849.2 343.434 1836.67 269.93C1830.14 231.619 1831.94 221.01 1845.19 219.865C1854.86 219.031 1856.96 221.714 1868.45 249.461C1890.4 302.459 1887.83 371 1888.08 426.683C1888.24 464.112 1888.66 495.011 1888.99 495.346C1891.95 498.308 1946.94 427.867 1957.07 414.963C1998.66 361.973 2020.84 297.533 2043.79 235.29C2046.82 227.069 2053.15 183.645 2064.33 194.829Z" fill="currentColor" />
<path d="M418.569 513.313C417.833 512.239 419 513 419 513C418.881 513.09 418.736 513.195 418.569 513.313Z" fill="currentColor" />
<path d="M442 277C442 289.703 431.703 300 419 300C406.297 300 396 289.703 396 277C396 264.297 406.297 254 419 254C431.703 254 442 264.297 442 277Z" fill="currentColor"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M1104.57 148.773C1142.83 152.708 1207.04 150.458 1234.3 144.227C1315.5 120.5 1374.22 24.6968 1279.21 2.288C1199.77 -16.4448 1105.31 62.7266 1051.5 115.5C966.425 97.689 751.927 64.805 598.405 74.811C550.262 77.946 527.394 81.332 499.42 89.466C492.63 91.441 483.7 94.041 479.575 95.244C452.581 103.12 416.014 131.564 406.089 152.407C389.441 187.369 423.749 227.835 470.013 227.806C487.702 227.796 494.522 222.266 479.248 220.319C453.295 217.012 428.6 203.151 420.575 187.389C412.15 170.84 416.219 157.808 436.474 136.463C472.247 98.765 567.269 83.525 699.075 94.346C769.255 100.109 973.932 125.194 1027.5 139.5C1027.5 139.5 1023.3 143.948 993.748 179.664C929.954 256.784 893.028 359.272 867.242 454.312C860.22 480.187 848.189 500.312 832.004 513.254C829.293 515.422 825.115 518.962 822.719 521.122C805.956 536.232 793.917 542.654 786.63 533.1C772.337 514.361 773.964 490.276 793.3 434.35C800.729 412.864 805.505 400.586 821.435 362.023C831.424 337.842 859.659 306.054 883.646 279.05C897.913 262.988 910.677 248.618 917.204 238.548C934.704 211.548 960.183 164.432 933.013 151.538C905.842 138.644 858.704 182.048 832.704 228.548C807.009 274.501 789.994 351.209 789.597 353.006C789.776 352.15 792.866 334.646 747.856 327.788C688.787 318.788 620.331 420.533 620.067 481.135C619.977 502.003 620.067 511.5 626.882 526.377C625.089 526.264 622.064 527.159 618.006 529.312C606.494 535.419 599.141 527.366 597.847 524.529C593.5 515 589.5 504 595.539 454.812C601.578 405.624 641.56 321.434 655.5 309C669.44 296.566 713 252.5 730.5 225.5C748 198.5 773.479 151.384 746.309 138.49C719.138 125.596 672 169 646 215.5C620 262 586.5 344.312 586.5 344.312C579.5 336 577.5 329.919 541.931 324.5C482.862 315.5 414.406 417.245 414.142 477.847C414.099 487.835 414.142 496.5 416 504C416 504 398.897 514.959 387.786 523.744C379.5 530.296 357.388 548.485 351 515.385C344.612 482.286 424.455 390.176 400.5 338.516C392.195 320.606 365.357 325.72 350.857 329.72C336.357 333.72 292.692 361.607 262.5 381.016C253.625 362.327 248.5 342.016 246 338.516C273.188 315.73 311.439 281.69 335.161 255.385C354.814 233.592 462.5 104.528 324.575 82.348C258.989 71.801 180.778 115.073 161.971 172.312C143.164 229.551 169.5 299.054 200.075 364.812C157.618 401.204 109.037 432.604 69.637 472.198C42.4527 502.924 16.0752 534.812 0.5 578.672C3.095 583.521 6.57801 580.019 8.66101 570.467C19.5752 541.312 41.6403 511.191 61.961 489.557C101.165 443.109 157.21 410.968 206.075 376.271C206.575 377.312 217.075 403.812 217.075 404.812C197.433 414.675 178.028 424.744 159.075 435.812C140.123 446.88 25.8453 504 17.528 593.369C13.3 638.799 43.985 681.416 91.075 695.516C111.504 701.632 161.951 694.374 186.674 681.761C232.467 658.416 267.654 637.163 290.668 590.734C321.047 529.448 289.927 451.569 267.5 392.516C292.856 374.853 315.857 354.72 338.857 344.72C361.857 334.72 385.786 333.468 374.836 354.697C357.12 389.042 335.5 422 327.5 457C319.5 492 322.989 522.64 335.5 539.812C348.011 556.984 382.974 537.353 387.268 534.348C391.562 531.343 398 526.854 401.575 524.373C404.964 522.022 415.522 515.466 418.569 513.313C417.833 512.239 419 513 419 513C418.881 513.09 418.736 513.195 418.569 513.313C419.286 514.359 421.808 517.147 428.975 524.076C443.497 538.117 461.576 549.198 479.5 546C499.926 542.356 522.517 517.066 541.931 495.179C550.042 486.034 555.096 486.797 558.051 498.927C571.589 554.5 604.236 552.217 623.076 535.677C626.807 532.402 628.614 529.793 628.761 528.18C638.141 536.902 682.191 572.215 746.587 507.262C748.695 502.836 749.153 501.876 750.609 509.001C753.63 523.784 764.47 539.975 774.715 545.006C787.88 551.47 813.021 543.024 828.317 530.724C842.332 519.455 845.242 520.307 844.144 535.354C843.218 548.061 846.267 547.868 855.276 547.301C857.483 547.162 860.048 547 863 547C873.236 547 889.99 515.849 907.544 483.211C915.715 468.019 924.059 452.505 932 439.66C957 399.221 1017.36 333.118 1026.32 354.549C1029.76 362.793 1027.33 380.841 1011.97 413.028C988.723 459.199 968.071 602.071 1046.16 527.684C1056.19 518.129 1060.11 522.355 1065.5 528.175C1066.19 528.91 1066.89 529.671 1067.63 530.432C1091.55 554.898 1134.01 553.692 1164.38 527.684C1170.64 522.324 1174.03 524.129 1175.72 533.712C1181.32 565.5 1226.13 536.343 1242.72 518.156C1258.81 500.52 1280.77 471.053 1292.54 451.306C1307.35 426.453 1312.26 415.869 1333.15 363.812C1337.76 352.33 1338.79 349.207 1340.91 347.994C1341.8 347.485 1342.88 347.313 1344.5 347C1347.87 346.35 1352.65 351.472 1358.7 357.947L1358.7 357.948C1362.49 362.004 1366.77 366.591 1371.51 370.622C1383.83 381.087 1380.39 394.575 1355.88 432.036C1335.08 463.82 1315.7 508.126 1344.5 540C1372.07 563.774 1415.33 531.434 1432 510C1425.95 570.272 1489.94 543.966 1514.41 522.426C1535.02 504.283 1535.9 499.366 1534.92 519.366C1533.96 539.215 1535.95 547.788 1548 547.788C1560.58 547.788 1561.52 543.266 1570.4 500.271L1570.57 499.483C1579.42 456.626 1602.1 403.501 1638.06 377.697C1660.51 361.591 1674.51 359.442 1681.55 371.02C1686.17 385.514 1676.84 415.235 1667.1 446.237C1651.66 495.401 1635.21 547.788 1671.78 547.788C1689.23 547.788 1733.61 510.79 1726.53 502.253C1724.84 500.222 1717.22 506.967 1708.28 514.884C1697.67 524.273 1685.21 535.311 1678.57 535.311C1671.89 535.311 1679.46 513.49 1689.47 484.607L1689.47 484.604L1689.48 484.595C1695.12 468.328 1701.53 449.823 1706.62 431.715C1727.25 341.312 1676.9 319.87 1616.51 378.475C1602.01 392.543 1600.99 387.385 1612.14 356.312C1614.24 350.456 1615.97 344.623 1617.66 338.909C1623.58 318.939 1629.07 300.42 1648.51 287.432C1679.5 266.729 1823.52 121.582 1755.4 101.353C1682.17 79.6079 1614.95 222.408 1602.5 271.5C1586.58 276.055 1545.57 282.322 1531.25 276.88C1527 275.265 1526.94 271.979 1530.88 258.489C1537.46 235.939 1536.19 227.812 1526.09 227.812C1517.81 227.812 1513.67 233.36 1503.53 258.021C1495.83 276.756 1495.05 277.257 1472.07 278.299C1428.96 280.255 1403.57 287.841 1403.57 298.768C1403.57 302.404 1407.53 303.319 1415.06 301.426C1424.24 299.12 1476.74 300.71 1484.5 301.426C1459.77 352.562 1438.67 429.953 1431.97 486.456C1429.43 507.933 1366.92 552.562 1362.38 539.236C1356.16 520.951 1365.9 497.465 1373.07 480.812C1402.86 411.603 1405.84 379.008 1383.46 367.357C1371.72 361.246 1352.79 351.183 1350 337.498C1347.63 325.854 1349.85 310.292 1357.91 275.812C1361.73 259.516 1362.18 248.249 1359.17 244.917C1356.02 241.434 1351.98 242.224 1343.07 248.065C1315.38 266.231 1305.83 301.337 1321.86 326.127C1327.42 334.73 1328.68 337.701 1323.5 352.5C1322.11 356.478 1320.81 360.266 1319.55 363.936C1311.87 386.376 1305.7 404.393 1288.58 434.312C1272.27 462.801 1262.05 475.801 1249.76 491.441L1249.76 491.445C1247.03 494.915 1244.2 498.515 1241.18 502.443C1236.08 509.083 1222.01 521.731 1218.03 523.255C1204.31 528.52 1208.67 466.511 1220 434.312C1223.02 425.731 1225.89 416.594 1228.8 407.314L1228.8 407.313C1234.45 389.314 1240.27 370.776 1247.68 354.711C1258.92 328.802 1250.66 309.209 1235.64 326.127C1221.27 342.3 1220.04 342.793 1211.18 335.954C1188.34 318.337 1148.48 325.39 1114 353.147C1084.39 376.984 1065.47 442.104 1061.55 479.733C1060.67 488.141 1059.37 489.338 1056.14 492.303C1054.06 494.211 1051.18 496.851 1047.1 502.617C1028.85 528.451 1010.41 542.148 1013.09 527.886C1017.69 503.357 1029.24 476.631 1040.22 451.21C1052.71 422.319 1064.46 395.114 1064.46 374.737C1064.46 341.017 1059.53 325 1039.5 325C978.32 325 943.462 390.788 919.581 439.66C916.007 440.906 915.017 439.689 915.833 435.05C931.221 347.488 988.799 247.865 1039.37 181.864C1065.84 147.325 1069.99 145.216 1104.57 148.773ZM1173.07 124.404C1101.55 123.056 1097.32 121.912 1113.32 108.262C1119.34 103.136 1125.45 97.7523 1131.69 92.2634C1131.69 92.2611 1131.69 92.2589 1131.7 92.2567C1131.7 92.2552 1131.7 92.2537 1131.7 92.2522L1131.71 92.2483L1131.71 92.2466L1131.71 92.2458L1131.71 92.244L1131.71 92.2429C1169.41 59.0647 1211.46 22.0532 1260.92 14.944C1311.04 7.73687 1326.98 53.695 1296.79 87.561C1274.14 112.973 1232.02 125.516 1173.07 124.404ZM1652 264.5C1620.77 285.133 1666.37 197.217 1712.5 146.265C1756.18 98.0361 1783.6 122.698 1739.57 178.812C1714.31 211.006 1686.67 241.611 1652 264.5ZM1519.59 493.43C1478.1 533.605 1454.74 549.751 1447.3 532.926C1434.01 476.5 1518.5 301.426 1518.5 301.426L1592.52 295.311C1587.75 314.754 1581.55 334.635 1575.31 354.643L1575.31 354.647C1566.26 383.652 1557.13 412.925 1552.17 441.52C1548.79 460.936 1542.05 471.681 1519.59 493.43ZM1136.88 358.254C1143.93 347.708 1152.89 341.268 1164.38 338.484C1192.61 331.642 1215.96 346.276 1205.74 364.4C1194.72 383.926 1187.64 418.491 1181.53 448.303C1178.77 461.783 1176.21 474.291 1173.57 483.998C1166.02 511.806 1120.26 540.315 1105.57 526.371C1073.98 496.397 1119.08 384.866 1136.88 358.254ZM188.098 194.685C198.926 141.523 244.25 101.255 300.503 94.82C322.284 92.328 350.798 99.654 364.174 111.178C402.637 144.316 342.312 235.46 240.901 327.788C238.062 322.875 234.972 317.672 231.755 312.257C209.588 274.942 181.412 227.512 188.098 194.685ZM556.994 443.7C552.829 466.209 508 525.447 481 534.348C428.975 551.5 447 461.5 465 421C483 380.5 502.958 349.642 523.979 342.579C545 335.516 557.405 340.579 563.575 342.818C580.016 348.785 582.55 364.265 571.589 391.778C565.128 407.99 560.189 426.441 556.994 443.7ZM181.099 440.812C201.58 427.824 216.167 422.458 222.075 420.312C224.691 431.895 228.267 443.325 231.85 454.777C235.01 464.876 238.175 474.992 240.692 485.246C246.795 510.109 248.218 565.478 243.149 580.812C237.164 598.914 209.562 636.803 195.383 646.379C135.529 686.802 82.378 692.776 53.075 662.373C2.00653 609.389 40.0224 552.873 82.575 512.205C102.382 493.281 130.581 472.848 181.099 440.812ZM710.5 236.5C702.962 246.111 662.5 289.757 639 312.257C646.093 296.429 653.03 279.533 659.901 262.797C684.396 203.133 708.057 145.5 735 145.5C769.5 145.5 716.619 228.699 710.5 236.5ZM782.235 371.538C771.207 400.39 761.751 430.434 753.948 461.34C746.144 492.246 738.95 520.484 686.925 537.636C634.9 554.788 652.925 464.788 670.925 424.288C688.925 383.788 708.883 352.93 729.904 345.867C757.17 336.706 772.597 344.576 782.235 371.538ZM921.704 158.548C962.007 156.538 903.323 241.746 897.204 249.548L825.704 325.305C825.704 325.305 881.401 160.558 921.704 158.548Z" fill="currentColor"/>
</svg>
</div><div class="p-2 font-bold text-2xl md:text-3xl text-center">ML Practitioner and Musician</div><hr><div class="lg:grid lg:grid-cols-2 p-8 lg:p-16"><div class="flex justify-center m-4"><img class="my-auto w-80 xl:96 rounded-3xl border-2 border-slate-200" src="/profile.jpg"></div><div><p class="mt-4 first:mt-0 text-lg">Hi! I&#39;m Siddharth Verma, a Research Engineer at Character AI working on Large Language Model (LLM) pretraining. Previously, I was a Senior ML Engineer training chatbots at Square. I also was an AI resident at Facebook AI Research working on scaling multimodal learning and improving reasoning capabilities of LLMs. I completed my undergraduate degree in Computer Science &amp; Music from UC Berkeley where I worked with Prof. Sergey Levine on Reinforcement Learning and its applications to Natural Language Processing.</p><p class="mt-4 first:mt-0 text-lg">My expertise lies in Natural Language Processing and Reinforcement Learning. I have trained LLMs upto 100B parameters and deployed them to production serving millions of users. I have also conducted extensive ML research in both academic and industrial settings, resulting in multiple published papers in venues such as NeurIPS and ACL.</p><p class="mt-4 first:mt-0 text-lg">When I&#39;m not training models or performing research, you can catch me practicing the piano, playing table tennis or tweaking my Emacs config.</p></div></div><div class="my-2 flex flex-row"><a class="m-4 px-4 py-2 border-2 border-slate-500 bg-slate-200 hover:bg-slate-400 font-bold text-indigo-600 rounded-md" href="mailto:siddharthverma314@gmail.com">Contact me</a><a class="m-4 px-4 py-2 border-2 border-slate-500 bg-slate-200 hover:bg-slate-400 font-bold text-indigo-600 rounded-md" href="/blog.html">Read Blog</a></div></div></div><div class="mx-auto flex flex-col items-center p-5"><div class="font-bold text-3xl p-3">Experience</div><div class="flex flex-wrap p-3" id="filter"><div>Filters:</div><div class="px-3"><input type="checkbox" checked="" onclick="update()"><label for="content-work"> work</label></div><div class="px-3"><input type="checkbox" checked="" onclick="update()"><label for="content-work"> education</label></div><div class="px-3"><input type="checkbox" checked="" onclick="update()"><label for="content-work"> research</label></div><div class="px-3"><input type="checkbox" checked="" onclick="update()"><label for="content-work"> honors</label></div></div></div><div id="content"><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="0"><div class="font-bold text-2xl">ğŸ’¼ Research Engineer</div><div class="text-xl">Character.ai</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Dec 2023 to Current</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“ New York NY</div></div><ul class="px-5 list-disc"><li>Contributed to all aspects of LLM pretraining from fundamental research to performant implementations</li><li>Implemented multiple MoE variants for our flagship model trained across our entire cluster of GPUs</li><li>Discovered the exact relation between attention and intelligence in LLMs</li><li>Designed scaling laws to predict a 5 order-of-magnitude extrapolation in validation loss with tight error bounds</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Using RL and Synthetic Data to Teach Chatbots to Avoid Certain Topics</div><div class="text-xl">Suppressing Pink Elephants with Direct Principle Feedback</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Feb 2024</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ Contributor</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸŒ ACL</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2402.07896">ArXiv</a></div></div><ul class="px-5 list-disc"><li>Investigated ILQL-based Reinforcement Learning for finetuning LLMs</li><li>Implemented automated GPT-4 based evaluation pipeline for judging model coherence</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Reviewer for EMNLP 2023</div><div class="text-xl">Peer review paper submissions</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Dec 2023</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="0"><div class="font-bold text-2xl">ğŸ’¼ Senior Machine Learning Engineer</div><div class="text-xl">Square</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Sep 2022 to Dec 2023</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“ Boston MA</div></div><ul class="px-5 list-disc"><li>Finetuned open-source LLMs on merchant-buyer conversations to suggest replies to incoming messages</li><li>Conducted an online A/B test and demonstrated a 5% increase in suggestion acceptance rate</li><li>Designed and implemented a multi-task training system to incorporate classification tasks into an LLM</li><li>Instruction finetuned FLAN-T5 on internal data and evaluated performance against individual classifiers</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Reviewer for ACL 2023</div><div class="text-xl">Peer review paper submissions</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jul 2023</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Investigating Reasoning Capabilities of Large Language Models</div><div class="text-xl">OPT-R: Enhacing Reasoning Capabilities of Large Language Models</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ May 2023</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ Contributor</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸŒ ACL Natural Language Reasoning and Structured Explanations workshop</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2305.12001">ArXiv</a></div></div><ul class="px-5 list-disc"><li>Curated dataset comprised of various reasoning tasks grouped by reasoning skills like Mathematical and Common Sense Reasoning.</li><li>Architected a Makefile based data pipeline to streamline the downloading and preprocessing of data from multiple sources.</li><li>Finetuned multiple sizes of OPT upto 13B parameters</li><li>Analyzed reasoning performance with respect to model size and reasoning skill.</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Empirical investigation of masking strategies and rates in Vision-Language Pretraining</div><div class="text-xl">Uniform Masking Prevails in Vision-Language Pretraining</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Dec 2022</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ First Author</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2212.05195">ArXiv</a></div></div><ul class="px-5 list-disc"><li>Conducted a large-scale experimental analysis of a 335M parameter Vision-Language model.</li><li>Designed a scientific experiment to analyze the effects of masking strategies and masking percent on downstream performance</li><li>Evaluated the model on multiple downstream tasks like VQA and NLVR and performed data analysis on the results.</li><li>Published findings on arxiv in a short-form paper revealing that masking strategy has negligible effect on performance</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Reviewer for EMNLP 2022</div><div class="text-xl">Peer review paper submissions</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Dec 2022</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Investigating Reasoning Capabilities of Large Language Models</div><div class="text-xl">ALERT: Adapting Language Models to Reasoning Tasks</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Oct 2022</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ Contributor</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸŒ ACL</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2212.08286">ArXiv</a></div></div><ul class="px-5 list-disc"><li>Curated dataset comprised of various reasoning tasks grouped by reasoning skills like Mathematical and Common Sense Reasoning.</li><li>Architected a Makefile based data pipeline to streamline the downloading and preprocessing of data from multiple sources.</li><li>Finetuned multiple sizes of OPT upto 13B parameters</li><li>Analyzed reasoning performance with respect to model size and reasoning skill.</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="0"><div class="font-bold text-2xl">ğŸ’¼ AI Resident</div><div class="text-xl">Meta (Facebook)</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Aug 2021 to Sep 2022</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“ Seattle WA</div></div><ul class="px-5 list-disc"><li>Wrote code to process 1TB of multimodal data using Rust and Parquet for a 20x speedup against Python</li><li>Automated the training LLMs of up to 13B parameters on large multi-node clusters with up to 64GPUs</li><li>Evaluated whether training on explanations improve reasoning capabilities of LLMs, and found that explanations mostly benefit mathematical reasoning</li><li>Analyzed effect of masking rates and masking strategies in multimodal learning, showing that increasing masking rate nullifies effects of different masking strategies</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Reviewer for SIGIR 2022</div><div class="text-xl">Peer review paper submissions</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ May 2022</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Reinforcement Learning based Chatbots using Large Language Models</div><div class="text-xl">CHAI: A Chatbot AI for Task-oriented Dialog with Offline Reinforcement Learning</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Apr 2022</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ First Author</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸŒ NAACL</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2204.08426">ArXiv</a></div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="/research/chai-acl-2022/">Webpage</a></div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://github.com/siddharthverma314/chai-naacl-2022">Code</a></div></div><ul class="px-5 list-disc"><li>Trained a model to negotiate a price for a product using data from Craigslist.</li><li>Architected an algorithm to fuse Reinforcement Learning with Language Models.</li><li>Implemented various Offline RL algorithms like CQL and EMaQ.</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="0"><div class="font-bold text-2xl">ğŸ’¼ Machine Learning Intern</div><div class="text-xl">Apple</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jun 2021 to Aug 2021</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“ Seattle WA</div></div><ul class="px-5 list-disc"><li>Implemented Transformer architecture from primitive operations for an in-house deep learning framework</li><li>Demonstrated correctness by replicating English-German translation results from &#39;Attention Is All You Need&#39;</li><li>Optimized self-attention for Apple Neural Engine by rewriting computation with supported operations</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Reinforcement Learning based Chatbots using Large Language Models</div><div class="text-xl">CHAI: A Chatbot AI for Task-oriented Dialog with Offline Reinforcement Learning</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jul 2021</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ First Author</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸŒ ICLR NeuCAIR workshop</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2204.08426">ArXiv</a></div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="/research/chai-acl-2022/">Webpage</a></div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://github.com/siddharthverma314/chai-naacl-2022">Code</a></div></div><ul class="px-5 list-disc"><li>Trained a model to negotiate a price for a product using data from Craigslist.</li><li>Architected an algorithm to fuse Reinforcement Learning with Language Models.</li><li>Implemented various Offline RL algorithms like CQL and EMaQ.</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="0"><div class="font-bold text-2xl">ğŸ’¼ Undergraduate Researcher at Robotic AI and Learning Lab</div><div class="text-xl">Berkeley Artificial Intelligence Research Lab</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jan 2019 to May 2021</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“ Berkeley CA</div></div><ul class="px-5 list-disc"><li>Worked with Prof. Sergey Levine and Prof. Chelsea Finn on RL and NLP in domains of robotics and chatbots</li><li>Designed and implemented a multi-agent RL algorithm to learn composable locomotive skills without manual environment resets, subsequently using them to solve a maze. Published at NeurIPS</li><li>Used Offline RL to finetune LLMs to bargain on craigslist items, beating supervised learning in human evals across all metrics. Accepted as oral presentation at NAACL</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="0"><div class="font-bold text-2xl">ğŸ’¼ Teaching Assistant, Deep Learning and Neural Networks</div><div class="text-xl">UC Berkeley EECS</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jan 2021 to May 2021</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“ Berkeley CA</div></div><ul class="px-5 list-disc"><li>Served as a TA for a deep learning fundamentals class teaching topics like logistic regression, convolutional neural networks, and transformers.</li><li>Led a 15-person discussion session to review material taught in lecture and held office hours for homework help</li><li>Designed exam problems for the final and beta-tested new homework assignments before releasing them to students</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="1"><div class="font-bold text-2xl">ğŸ“ UC Berkeley</div><div class="text-xl">BA Computer Science &amp; Music</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Aug 2017 to May 2021</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“œ 3.965</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ High Distinction</div><div class="text-xl">Graduated with High Distinction. Equivalent to magna cum laude.</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ May 2021</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Phi Beta Kappa</div><div class="text-xl">Honor society for top graduates in college of L&amp;S.</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jan 2021</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="2"><div class="font-bold text-2xl">ğŸ§ Reset-free robotic skill learning via Adversarial RL</div><div class="text-xl">Continual Learning of Control Primitives: Skill Discovery via Reset-Games</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Nov 2020</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ˜ƒ CoFirst Author</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸŒ NeurIPS</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://arxiv.org/abs/https://arxiv.org/abs/2011.05286">ArXiv</a></div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ”— <a class="underline" href="https://github.com/siddharthverma314/clcp-neurips-2020">Code</a></div></div><ul class="px-5 list-disc"><li>Designed an RL algorithm to learn skills without manual interventions to reset the environment</li><li>Implemented a Python RL framework using Pytorch and open-sourced it on Github.</li><li>Trained a four-legged robot to walk and subsequently solve a maze using learned skills</li></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ EECS Honors</div><div class="text-xl">Awarded to the top students in EECS/CS who perform research.</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jan 2020</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Dean&#39;s List</div><div class="text-xl">Awarded semesterly to the top 10% of undergraduates.</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jan 2019</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="3"><div class="font-bold text-2xl">ğŸ¥‚ Upsilon Pi Epsilon</div><div class="text-xl">Computer Science Honor Society. Was on the board of directors.</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Jan 2019</div></div><ul class="px-5 list-disc"></ul></div><div class="mx-auto px-8 md:px-32 lg:px-64 py-4 md:py-8 odd:bg-slate-100" data-content="1"><div class="font-bold text-2xl">ğŸ“ The International School Bangalore</div><div class="text-xl">International Baccalaureate Diploma</div><div class="flex flex-wrap"><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ—“ï¸ Aug 2015 to May 2017</div><div class="m-2 px-3 rounded-md border-2 border-slate-500 bg-indigo-800 text-slate-200">ğŸ“œ 48.0</div></div><ul class="px-5 list-disc"></ul></div></div></body></html>